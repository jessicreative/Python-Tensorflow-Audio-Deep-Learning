{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mlp_tensorflow.ipynb","provenance":[],"authorship_tag":"ABX9TyPR7io0AMbSX83g4DN6j+c/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvw3krgLzoXe","executionInfo":{"status":"ok","timestamp":1629486089890,"user_tz":420,"elapsed":12048,"user":{"displayName":"Jessica Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjo8h1T9XCyNgOywfWbXigBJ8MJZibnbBsYPeOHog=s64","userId":"18309574365320758784"}},"outputId":"b5b52062-dc02-4f00-dce9-17faf397f2a4"},"source":["import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from random import random\n","\n","\n","def generate_dataset(num_samples, test_size=0.33):\n","    \"\"\"Generates train/test data for sum operation\n","    :param num_samples (int): Num of total samples in dataset\n","    :param test_size (int): Ratio of num_samples used as test set\n","    :return x_train (ndarray): 2d array with input data for training\n","    :return x_test (ndarray): 2d array with input data for testing\n","    :return y_train (ndarray): 2d array with target data for training\n","    :return y_test (ndarray): 2d array with target data for testing\n","    \"\"\"\n","\n","    # build inputs/targets for sum operation: y[0][0] = x[0][0] + x[0][1]\n","    x = np.array([[random()/2 for _ in range(2)] for _ in range(num_samples)])\n","    y = np.array([[i[0] + i[1]] for i in x])\n","\n","    # split dataset into test and training sets\n","    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n","    return x_train, x_test, y_train, y_test\n","\n","if __name__ == \"__main__\":\n","  x_train, x_test, y_train, y_test = generate_dataset(5000,0.3)\n","  print(\"x_test: \\n {}\".format(x_test))\n","  print(\"y_test: \\n {}\".format(y_test))\n","\n","\n","# build model: 2->5->1\n","model = tf.keras.Sequential([\n","  tf.keras.layers.Dense(5, input_dim=2, activation=\"sigmoid\"),\n","  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","# compile model\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n","model.compile(optimizer=optimizer, loss=\"MSE\")\n","\n","# train model\n","model.fit(x_train,y_train,epochs=100)\n","\n","# evaluate model\n","print(\"\\nModel evaluation:\")\n","model.evaluate(x_test,y_test,verbose=1)\n","\n","# make predictions\n","data = np.array([[0.1,0.2],[0.2,0.2]])\n","predictions = model.predict(data)\n","\n","print(\"\\nSome predictions:\")\n","for d, p in zip(data, predictions):\n","  print(\"{}+{}={}\".format(d[0],d[1],p[0]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["x_test: \n"," [[0.02036869 0.05688736]\n"," [0.20319381 0.12869635]\n"," [0.19447736 0.19381302]\n"," ...\n"," [0.03116615 0.30818143]\n"," [0.11944986 0.44320798]\n"," [0.48360419 0.00485577]]\n","y_test: \n"," [[0.07725606]\n"," [0.33189016]\n"," [0.38829038]\n"," ...\n"," [0.33934758]\n"," [0.56265784]\n"," [0.48845996]]\n","Epoch 1/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0432\n","Epoch 2/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0414\n","Epoch 3/100\n","110/110 [==============================] - 0s 995us/step - loss: 0.0409\n","Epoch 4/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0404\n","Epoch 5/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0399\n","Epoch 6/100\n","110/110 [==============================] - 0s 906us/step - loss: 0.0395\n","Epoch 7/100\n","110/110 [==============================] - 0s 977us/step - loss: 0.0390\n","Epoch 8/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0384\n","Epoch 9/100\n","110/110 [==============================] - 0s 981us/step - loss: 0.0379\n","Epoch 10/100\n","110/110 [==============================] - 0s 977us/step - loss: 0.0374\n","Epoch 11/100\n","110/110 [==============================] - 0s 995us/step - loss: 0.0369\n","Epoch 12/100\n","110/110 [==============================] - 0s 892us/step - loss: 0.0363\n","Epoch 13/100\n","110/110 [==============================] - 0s 891us/step - loss: 0.0357\n","Epoch 14/100\n","110/110 [==============================] - 0s 910us/step - loss: 0.0352\n","Epoch 15/100\n","110/110 [==============================] - 0s 993us/step - loss: 0.0345\n","Epoch 16/100\n","110/110 [==============================] - 0s 995us/step - loss: 0.0339\n","Epoch 17/100\n","110/110 [==============================] - 0s 980us/step - loss: 0.0332\n","Epoch 18/100\n","110/110 [==============================] - 0s 980us/step - loss: 0.0326\n","Epoch 19/100\n","110/110 [==============================] - 0s 916us/step - loss: 0.0319\n","Epoch 20/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0312\n","Epoch 21/100\n","110/110 [==============================] - 0s 897us/step - loss: 0.0304\n","Epoch 22/100\n","110/110 [==============================] - 0s 914us/step - loss: 0.0297\n","Epoch 23/100\n","110/110 [==============================] - 0s 909us/step - loss: 0.0289\n","Epoch 24/100\n","110/110 [==============================] - 0s 910us/step - loss: 0.0281\n","Epoch 25/100\n","110/110 [==============================] - 0s 948us/step - loss: 0.0273\n","Epoch 26/100\n","110/110 [==============================] - 0s 998us/step - loss: 0.0265\n","Epoch 27/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0256\n","Epoch 28/100\n","110/110 [==============================] - 0s 864us/step - loss: 0.0248\n","Epoch 29/100\n","110/110 [==============================] - 0s 989us/step - loss: 0.0239\n","Epoch 30/100\n","110/110 [==============================] - 0s 862us/step - loss: 0.0230\n","Epoch 31/100\n","110/110 [==============================] - 0s 882us/step - loss: 0.0222\n","Epoch 32/100\n","110/110 [==============================] - 0s 918us/step - loss: 0.0213\n","Epoch 33/100\n","110/110 [==============================] - 0s 994us/step - loss: 0.0204\n","Epoch 34/100\n","110/110 [==============================] - 0s 912us/step - loss: 0.0196\n","Epoch 35/100\n","110/110 [==============================] - 0s 991us/step - loss: 0.0187\n","Epoch 36/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0179\n","Epoch 37/100\n","110/110 [==============================] - 0s 890us/step - loss: 0.0170\n","Epoch 38/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0162\n","Epoch 39/100\n","110/110 [==============================] - 0s 900us/step - loss: 0.0154\n","Epoch 40/100\n","110/110 [==============================] - 0s 915us/step - loss: 0.0146\n","Epoch 41/100\n","110/110 [==============================] - 0s 912us/step - loss: 0.0138\n","Epoch 42/100\n","110/110 [==============================] - 0s 877us/step - loss: 0.0131\n","Epoch 43/100\n","110/110 [==============================] - 0s 996us/step - loss: 0.0123\n","Epoch 44/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0116\n","Epoch 45/100\n","110/110 [==============================] - 0s 999us/step - loss: 0.0110\n","Epoch 46/100\n","110/110 [==============================] - 0s 953us/step - loss: 0.0103\n","Epoch 47/100\n","110/110 [==============================] - 0s 873us/step - loss: 0.0097\n","Epoch 48/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0091\n","Epoch 49/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0086\n","Epoch 50/100\n","110/110 [==============================] - 0s 998us/step - loss: 0.0080\n","Epoch 51/100\n","110/110 [==============================] - 0s 997us/step - loss: 0.0075\n","Epoch 52/100\n","110/110 [==============================] - 0s 911us/step - loss: 0.0070\n","Epoch 53/100\n","110/110 [==============================] - 0s 888us/step - loss: 0.0066\n","Epoch 54/100\n","110/110 [==============================] - 0s 994us/step - loss: 0.0062\n","Epoch 55/100\n","110/110 [==============================] - 0s 985us/step - loss: 0.0058\n","Epoch 56/100\n","110/110 [==============================] - 0s 982us/step - loss: 0.0054\n","Epoch 57/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0051\n","Epoch 58/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0047\n","Epoch 59/100\n","110/110 [==============================] - 0s 907us/step - loss: 0.0044\n","Epoch 60/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0041\n","Epoch 61/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0039\n","Epoch 62/100\n","110/110 [==============================] - 0s 902us/step - loss: 0.0036\n","Epoch 63/100\n","110/110 [==============================] - 0s 989us/step - loss: 0.0034\n","Epoch 64/100\n","110/110 [==============================] - 0s 952us/step - loss: 0.0032\n","Epoch 65/100\n","110/110 [==============================] - 0s 884us/step - loss: 0.0030\n","Epoch 66/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0028\n","Epoch 67/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0026\n","Epoch 68/100\n","110/110 [==============================] - 0s 986us/step - loss: 0.0024\n","Epoch 69/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0023\n","Epoch 70/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0022\n","Epoch 71/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0020\n","Epoch 72/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0019\n","Epoch 73/100\n","110/110 [==============================] - 0s 992us/step - loss: 0.0018\n","Epoch 74/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0017\n","Epoch 75/100\n","110/110 [==============================] - 0s 869us/step - loss: 0.0016\n","Epoch 76/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0015\n","Epoch 77/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0014\n","Epoch 78/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0013\n","Epoch 79/100\n","110/110 [==============================] - 0s 947us/step - loss: 0.0013\n","Epoch 80/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0012\n","Epoch 81/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0011\n","Epoch 82/100\n","110/110 [==============================] - 0s 897us/step - loss: 0.0011\n","Epoch 83/100\n","110/110 [==============================] - 0s 1ms/step - loss: 0.0010\n","Epoch 84/100\n","110/110 [==============================] - 0s 872us/step - loss: 9.9356e-04\n","Epoch 85/100\n","110/110 [==============================] - 0s 987us/step - loss: 9.4911e-04\n","Epoch 86/100\n","110/110 [==============================] - 0s 1ms/step - loss: 9.0790e-04\n","Epoch 87/100\n","110/110 [==============================] - 0s 1ms/step - loss: 8.6967e-04\n","Epoch 88/100\n","110/110 [==============================] - 0s 912us/step - loss: 8.3445e-04\n","Epoch 89/100\n","110/110 [==============================] - 0s 1ms/step - loss: 8.0156e-04\n","Epoch 90/100\n","110/110 [==============================] - 0s 965us/step - loss: 7.7075e-04\n","Epoch 91/100\n","110/110 [==============================] - 0s 1ms/step - loss: 7.4266e-04\n","Epoch 92/100\n","110/110 [==============================] - 0s 1ms/step - loss: 7.1704e-04\n","Epoch 93/100\n","110/110 [==============================] - 0s 908us/step - loss: 6.9289e-04\n","Epoch 94/100\n","110/110 [==============================] - 0s 1ms/step - loss: 6.7045e-04\n","Epoch 95/100\n","110/110 [==============================] - 0s 1ms/step - loss: 6.4970e-04\n","Epoch 96/100\n","110/110 [==============================] - 0s 973us/step - loss: 6.3039e-04\n","Epoch 97/100\n","110/110 [==============================] - 0s 1ms/step - loss: 6.1279e-04\n","Epoch 98/100\n","110/110 [==============================] - 0s 884us/step - loss: 5.9640e-04\n","Epoch 99/100\n","110/110 [==============================] - 0s 900us/step - loss: 5.8099e-04\n","Epoch 100/100\n","110/110 [==============================] - 0s 966us/step - loss: 5.6712e-04\n","\n","Model evaluation:\n","47/47 [==============================] - 0s 896us/step - loss: 5.6516e-04\n","\n","Some predictions:\n","0.1+0.2=0.2993955612182617\n","0.2+0.2=0.3961338698863983\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L_obNdF-6x5m"},"source":[""],"execution_count":null,"outputs":[]}]}